{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相应的库\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始设置\n",
    "im_height = 224 \n",
    "im_width = 224\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "num_classes = 3\n",
    "save_path = './save_weights/res50-{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "\n",
    "image_path = 'G:/dataset/panicle_period/'\n",
    "train_dir = image_path + \"train\"\n",
    "val_dir = image_path + \"val\"\n",
    "test_dir = image_path + \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "train_image_generator = ImageDataGenerator(\n",
    "    preprocessing_function=keras.applications.resnet50.preprocess_input,\n",
    "#     rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     rotation_range = 20,\n",
    "#     brightness_range = (1.2, 1.5)\n",
    ")\n",
    "val_image_generator = ImageDataGenerator(\n",
    "    preprocessing_function=keras.applications.resnet50.preprocess_input,\n",
    ")\n",
    "test_image_generator = ImageDataGenerator(\n",
    "    preprocessing_function=keras.applications.resnet50.preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39688 images belonging to 3 classes.\n",
      "Found 13231 images belonging to 3 classes.\n",
      "Found 13231 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 生成数据\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           shuffle=True,\n",
    "                                                           color_mode=\"rgb\",\n",
    "                                                           target_size=(im_height, im_width),\n",
    "                                                           class_mode='categorical')\n",
    "total_train = train_data_gen.n\n",
    "\n",
    "val_data_gen = val_image_generator.flow_from_directory( directory=val_dir,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=False,\n",
    "                                                       color_mode=\"rgb\",\n",
    "                                                          target_size=(im_height, im_width),\n",
    "                                                          class_mode='categorical')\n",
    "total_val = val_data_gen.n\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory( directory=test_dir,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=False,\n",
    "                                                         color_mode=\"rgb\",\n",
    "                                                          target_size=(im_height, im_width),\n",
    "                                                          class_mode='categorical')\n",
    "total_test = test_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_for_0 = (1 / 1341)*(total_train)/2.0 \n",
    "# weight_for_1 = (1 / 3875)*(total_train)/2.0\n",
    "\n",
    "# class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "# print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "# print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 301059    \n",
      "=================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "covn_base = tf.keras.applications.ResNet50(weights='imagenet', include_top = False,\n",
    "                                              input_shape=(im_height,im_width,3))\n",
    "covn_base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(covn_base)\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling2D()) #GAP层\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer = Adam(lr=0.0001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     model.load_weights(\"./save_weights/DenseNet201.ckpt\")\n",
    "#     print(\"载入模型成果！继续训练模型\")\n",
    "# except :    \n",
    "#     print(\"载入模型失败！开始训练一个新模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "1240/1240 [==============================] - 129s 104ms/step - loss: 0.2163 - accuracy: 0.9189 - val_loss: 0.1442 - val_accuracy: 0.9501\n",
      "Epoch 2/50\n",
      "1240/1240 [==============================] - 131s 105ms/step - loss: 0.1305 - accuracy: 0.9551 - val_loss: 0.1188 - val_accuracy: 0.9590\n",
      "Epoch 3/50\n",
      "1240/1240 [==============================] - 126s 102ms/step - loss: 0.1168 - accuracy: 0.9610 - val_loss: 0.1076 - val_accuracy: 0.9641\n",
      "Epoch 4/50\n",
      "1240/1240 [==============================] - 130s 105ms/step - loss: 0.1024 - accuracy: 0.9657 - val_loss: 0.1635 - val_accuracy: 0.9527\n",
      "Epoch 5/50\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0894 - accuracy: 0.9693 - val_loss: 0.0900 - val_accuracy: 0.9709\n",
      "Epoch 6/50\n",
      "1240/1240 [==============================] - 126s 102ms/step - loss: 0.0910 - accuracy: 0.9702 - val_loss: 0.1044 - val_accuracy: 0.9696\n",
      "Epoch 7/50\n",
      "1240/1240 [==============================] - 125s 101ms/step - loss: 0.0790 - accuracy: 0.9739 - val_loss: 0.0926 - val_accuracy: 0.9719\n",
      "Epoch 8/50\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0828 - accuracy: 0.9734 - val_loss: 0.0887 - val_accuracy: 0.9741\n",
      "Epoch 9/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.1011 - val_accuracy: 0.9688\n",
      "Epoch 10/50\n",
      "1240/1240 [==============================] - 125s 100ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 0.0937 - val_accuracy: 0.9731\n",
      "Epoch 11/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9759\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0734 - accuracy: 0.9759 - val_loss: 0.0995 - val_accuracy: 0.9734\n",
      "Epoch 12/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.0791 - val_accuracy: 0.9768\n",
      "Epoch 13/50\n",
      "1240/1240 [==============================] - 125s 101ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0775 - val_accuracy: 0.9785\n",
      "Epoch 14/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0388 - accuracy: 0.9863 - val_loss: 0.0753 - val_accuracy: 0.9792\n",
      "Epoch 15/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.0727 - val_accuracy: 0.9795\n",
      "Epoch 16/50\n",
      "1240/1240 [==============================] - 123s 100ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 0.0714 - val_accuracy: 0.9799\n",
      "Epoch 17/50\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0748 - val_accuracy: 0.9787\n",
      "Epoch 18/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.0722 - val_accuracy: 0.9796\n",
      "Epoch 19/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9881\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.0752 - val_accuracy: 0.9790\n",
      "Epoch 20/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 0.0701 - val_accuracy: 0.9805\n",
      "Epoch 21/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.0700 - val_accuracy: 0.9802\n",
      "Epoch 22/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 0.0697 - val_accuracy: 0.9802\n",
      "Epoch 23/50\n",
      "1240/1240 [==============================] - 122s 99ms/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 0.0693 - val_accuracy: 0.9802\n",
      "Epoch 24/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
      "Epoch 25/50\n",
      "1240/1240 [==============================] - 125s 101ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
      "Epoch 26/50\n",
      "1240/1240 [==============================] - 123s 100ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.0689 - val_accuracy: 0.9799\n",
      "Epoch 27/50\n",
      "1240/1240 [==============================] - 126s 102ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
      "Epoch 28/50\n",
      "1240/1240 [==============================] - 131s 105ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 0.0694 - val_accuracy: 0.9800\n",
      "Epoch 29/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 30/50\n",
      "1240/1240 [==============================] - 121s 98ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.0685 - val_accuracy: 0.9804\n",
      "Epoch 31/50\n",
      "1240/1240 [==============================] - 121s 98ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 32/50\n",
      "1240/1240 [==============================] - 121s 97ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.0687 - val_accuracy: 0.9802\n",
      "Epoch 33/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9896\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "1240/1240 [==============================] - 126s 102ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 34/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 35/50\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 36/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9905\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 37/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 38/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 39/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9891\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "1240/1240 [==============================] - 120s 97ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 40/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0289 - accuracy: 0.9890 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 41/50\n",
      "1240/1240 [==============================] - 119s 96ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 42/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9898\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "1240/1240 [==============================] - 125s 101ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 43/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 44/50\n",
      "1240/1240 [==============================] - 121s 98ms/step - loss: 0.0284 - accuracy: 0.9891 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 45/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9886\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.0308 - accuracy: 0.9886 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 46/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 47/50\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 48/50\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9894\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0289 - accuracy: 0.9894 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 49/50\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
      "Epoch 50/50\n",
      "1240/1240 [==============================] - 122s 98ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.0686 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# 监视’val_loss’的变化，如果两个轮次不变学习率衰减为原来的1/10\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                monitor='val_loss', \n",
    "                                factor=0.1, \n",
    "                                patience=3, \n",
    "                                mode='auto',\n",
    "                                verbose=1\n",
    "                             )\n",
    "\n",
    "# 设置模型保存路径，且根据val_acc保存最优模型\n",
    "checkpoint = ModelCheckpoint(\n",
    "                                filepath=save_path,\n",
    "                                monitor='val_accuracy', \n",
    "                                save_weights_only=False, \n",
    "                                save_best_only=True, \n",
    "                                mode='auto',\n",
    "                                period=5\n",
    "                            )\n",
    "\n",
    "history = model.fit(x=train_data_gen,\n",
    "                    steps_per_epoch=total_train // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_data_gen,\n",
    "                    validation_steps=total_val // batch_size,\n",
    "                    verbose=1,\n",
    "#                     class_weight=class_weight,\n",
    "                    callbacks=[checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-98e0a7f90cda>:47: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "[[1999   19    3]\n",
      " [  27 4597  125]\n",
      " [   5  130 6326]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(cm, target_names,title='Confusion matrix',cmap=None,normalize=False):\n",
    "    print(cm)\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm)) #计算准确率\n",
    "#     misclass = 1 - accuracy #计算错误率\n",
    "    precision = cm[0][0]/cm.sum(axis=0)[0]\n",
    "    recall = cm[0][0]/cm.sum(axis=1)[0]\n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues') #颜色设置成蓝色\n",
    "    plt.figure(figsize=(5, 4)) #设置窗口尺寸\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap) #显示图片\n",
    "    plt.title(title) #显示标题\n",
    "    plt.colorbar() #绘制颜色条\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45) #x坐标标签旋转45度\n",
    "        plt.yticks(tick_marks, target_names) #y坐标\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float32') / cm.sum(axis=1)\n",
    "        cm = np.round(cm,2) #对数字保留两位小数\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    #将cm.shape[0]、cm.shape[1]中的元素组成元组，遍历元组中每一个数字\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): \n",
    "        if normalize: #标准化\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), #保留两位小数\n",
    "                     horizontalalignment=\"center\",  #数字在方框中间\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")  #设置字体颜色\n",
    "        else:  #非标准化\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",  #数字在方框中间\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\") #设置字体颜色\n",
    "\n",
    "    plt.tight_layout() #自动调整子图参数,使之填充整个图像区域\n",
    "    plt.ylabel('True label') #y方向上的标签\n",
    "    #x方向上的标签\n",
    "    plt.xlabel(\"Predicted label\\n\\naccuracy={:0.4f}\\n precision={:0.4f}\\n recall={:0.4f}\\n F1={:0.4f}\"\n",
    "               .format(accuracy, precision, recall, f1))\n",
    "#     plt.savefig(\"cm_cnn.png\")\n",
    "    plt.show() #显示图片\n",
    "labels = ['1','2','3']\n",
    "\n",
    "# 预测验证集数据整体准确率\n",
    "Y_pred = model.predict_generator(test_data_gen, total_test // batch_size + 1)\n",
    "# 将预测的结果转化为one hit向量\n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1)\n",
    "# 计算混淆矩阵\n",
    "confusion_mtx = confusion_matrix(y_true = test_data_gen.classes,y_pred = Y_pred_classes)\n",
    "# 绘制混淆矩阵\n",
    "plot_confusion_matrix(confusion_mtx, normalize=True, target_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'G:/dataset/panicle_period/val/NORMAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e028d606c483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 遍历验证集的图片\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mval_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"val/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnormal_dirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'NORMAL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpneumonia_dirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'PNEUMONIA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg_path1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'G:/dataset/panicle_period/val/NORMAL'"
     ]
    }
   ],
   "source": [
    "# 遍历验证集的图片\n",
    "val_dir = image_path + \"val/\"\n",
    "normal_dirs = os.listdir(val_dir+'NORMAL')\n",
    "pneumonia_dirs = os.listdir(val_dir+'PNEUMONIA')\n",
    "img_path1 = []\n",
    "num=0\n",
    "for i in normal_dirs:                             \n",
    "    if os.path.splitext(i)[1] == \".jpeg\":   \n",
    "        img_path1.append(val_dir+\"NORMAL/\"+ i)\n",
    "        num+=1\n",
    "    if(num>=12):\n",
    "        break\n",
    "for i in pneumonia_dirs:                             \n",
    "    if os.path.splitext(i)[1] == \".jpeg\":   \n",
    "        img_path1.append(val_dir+\"PNEUMONIA/\"+i)\n",
    "        num+=1\n",
    "    if(num>=12):\n",
    "        break\n",
    "# print(img_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "#获取数据集的类别编码\n",
    "class_indices = train_data_gen.class_indices \n",
    "#将编码和对应的类别存入字典\n",
    "inverse_dict = dict((val, key) for key, val in class_indices.items()) \n",
    "fig = plt.figure(figsize=(15,12))\n",
    "a=1\n",
    "#加载测试图片\n",
    "for i in img_path1:\n",
    "    img = Image.open(i)\n",
    "    # 将图片resize到224x224大小\n",
    "    img = img.resize((im_width, im_height))\n",
    "    #将灰度图转化为RGB模式\n",
    "    img = img.convert(\"RGB\")\n",
    "    # 归一化\n",
    "    img1 = np.array(img) / 255.\n",
    "    # 将图片增加一个维度，目的是匹配网络模型\n",
    "    img1 = (np.expand_dims(img1, 0))\n",
    "    #将预测结果转化为概率值\n",
    "    result = np.squeeze(model.predict(img1))\n",
    "    predict_class = np.argmax(result)\n",
    "    #print(inverse_dict[int(predict_class)],result[predict_class])\n",
    "    plt.subplot(3,4,a)\n",
    "    a+=1\n",
    "    #将预测的结果打印在图片上面\n",
    "    plt.title([inverse_dict[int(predict_class)],result[predict_class]])\n",
    "    #显示图片\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
